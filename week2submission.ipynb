{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZM2iFOwih53zBLvC8eqSD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShrutiD-05/EWasteGenerationClassification/blob/main/week2submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsRyAdsTvFoT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf  # Core TensorFlow library\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks  # Layers, model creation, optimizers, and training callbacks\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model  # For sequential model architecture and loading saved models\n",
        "\n",
        "from tensorflow.keras.applications import EfficientNetV2B0  # Pretrained EfficientNetV2B0 model for transfer learning\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input  # Preprocessing function specific to EfficientNet\n",
        "\n",
        "import numpy as np  # Numerical operations and array handling\n",
        "\n",
        "import matplotlib.pyplot as plt  # Plotting graphs and images\n",
        "\n",
        "import seaborn as sns  # Plotting graphs and images\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report  # Evaluation metrics for classification models\n",
        "\n",
        "import gradio as gr  # Web interface library to deploy and test ML models\n",
        "\n",
        "from PIL import Image  # For image file loading and basic image operations\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testpath= r'D:\\edunet\\E_waste_classification\\modified-dataset\\test'\n",
        "trainpath= r'D:\\edunet\\E_waste_classification\\modified-dataset\\train'\n",
        "validpath = r'D:\\edunet\\E_waste_classification\\modified-dataset\\val'"
      ],
      "metadata": {
        "id": "dxTY5XxlX-i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datatest=tf.keras.utils.image_dataset_from_directory(testpath,shuffle = False, image_size = (128,128), batch_size = 32, validation_split= False)"
      ],
      "metadata": {
        "id": "_CwjGvJgYaFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datavalid = tf.keras.utils.image_dataset_from_directory(validpath,shuffle = True, image_size = (128,128), batch_size = 32, validation_split= False)"
      ],
      "metadata": {
        "id": "winiP7wWYmbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(datatrain.class_names))\n",
        "class_names = datatrain.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "J297a_A0Yqgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the sample data:"
      ],
      "metadata": {
        "id": "qBozwwF8eBm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set the size of the entire figure (width=10, height=10 inches)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Take one batch from the dataset and iterate over the images and labels\n",
        "for images, labels in datatrain.take(1):\n",
        "    # Display the first 12 images from the batch\n",
        "    for i in range(12):\n",
        "        # Create a 4x3 grid of subplots and select the (i+1)th position\n",
        "        ax = plt.subplot(4, 3, i + 1)\n",
        "\n",
        "        # Display the image; convert the tensor to a NumPy array and ensure correct type\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "        # Set the title of the subplot to the class name of the image\n",
        "        plt.title(class_names[labels[i]])\n",
        "\n",
        "        # Remove axis ticks and labels for clarity\n",
        "        plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "liZzUmOnYwpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_distribution(dataset, title=\"Class Distribution\"):\n",
        "    \"\"\"\n",
        "    Plots the number of items per class in a given dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: A tf.data.Dataset object created using image_dataset_from_directory\n",
        "        title: Title for the plot (e.g., 'Train Data Distribution')\n",
        "    \"\"\"\n",
        "\n",
        "    class_counts = {}  # Dictionary to hold the count of each class\n",
        "\n",
        "    # Iterate through the batches in the dataset\n",
        "    for images, labels in dataset:\n",
        "        # Convert labels tensor to numpy array and loop through each label\n",
        "        for label in labels.numpy():\n",
        "            class_name = dataset.class_names[label]  # Get class name using label index\n",
        "            # Increment the count for this class\n",
        "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
        "\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    class_names = list(class_counts.keys())  # List of class names\n",
        "    counts = list(class_counts.values())     # Corresponding counts for each class\n",
        "\n",
        "\n",
        "    # Create the bar plot\n",
        "    plt.figure(figsize=(10, 6))  # Set the figure size\n",
        "    plt.bar(class_names, counts, color='skyblue')  # Draw bars with class counts\n",
        "    plt.xlabel(\"Class\")  # X-axis label\n",
        "    plt.ylabel(\"Number of Items\")  # Y-axis label\n",
        "    plt.title(title)  # Plot title\n",
        "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "    plt.tight_layout()  # Adjust layout to prevent clipping\n",
        "    plt.show()  # Display the plot\n",
        "\n",
        "\n",
        "plot_class_distribution(datatrain, \"Training Data Distribution\")\n",
        "plot_class_distribution(datavalid, \"Validation Data Distribution\")\n",
        "plot_class_distribution(datatest, \"Test Data Distribution\")"
      ],
      "metadata": {
        "id": "MG_5-3RuY1uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing:"
      ],
      "metadata": {
        "id": "saIT3ZweeyiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "])"
      ],
      "metadata": {
        "id": "8vU_uQPcdrTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model selection:"
      ],
      "metadata": {
        "id": "3wdt1Ng4e45g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetV2B0(\n",
        "    input_shape=(128, 128, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "KMvQzuyQdtjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model architecture:"
      ],
      "metadata": {
        "id": "TwipbU2sfnsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(128, 128, 3)),\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['Accuracy'])"
      ],
      "metadata": {
        "id": "niCosg-TfrSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an EarlyStopping callback to stop training when validation loss stops improving\n",
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',            # Metric to monitor (validation loss here)\n",
        "    patience=3,                   # Number of epochs to wait after last improvement before stopping\n",
        "    restore_best_weights=True     # After stopping, restore the model weights from the epoch with the best val_loss\n",
        ")\n"
      ],
      "metadata": {
        "id": "sUX311j6f0Hp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}